#!/usr/bin/env bash

# jn_ap_op2 main_build
# 
# This wrapper script is auto-generated by viash 0.8.5 and is thus a derivative
# work thereof. This software comes with ABSOLUTELY NO WARRANTY from Data
# Intuitive.
# 
# The component may contain files which fall under a different license. The
# authors of this component should specify the license in the header of such
# files, or include a separate license file detailing the licenses of all included
# files.

set -e

if [ -z "$VIASH_TEMP" ]; then
  VIASH_TEMP=${VIASH_TEMP:-$VIASH_TMPDIR}
  VIASH_TEMP=${VIASH_TEMP:-$VIASH_TEMPDIR}
  VIASH_TEMP=${VIASH_TEMP:-$VIASH_TMP}
  VIASH_TEMP=${VIASH_TEMP:-$TMPDIR}
  VIASH_TEMP=${VIASH_TEMP:-$TMP}
  VIASH_TEMP=${VIASH_TEMP:-$TEMPDIR}
  VIASH_TEMP=${VIASH_TEMP:-$TEMP}
  VIASH_TEMP=${VIASH_TEMP:-/tmp}
fi

# define helper functions
# ViashQuote: put quotes around non flag values
# $1     : unquoted string
# return : possibly quoted string
# examples:
#   ViashQuote --foo      # returns --foo
#   ViashQuote bar        # returns 'bar'
#   Viashquote --foo=bar  # returns --foo='bar'
function ViashQuote {
  if [[ "$1" =~ ^-+[a-zA-Z0-9_\-]+=.+$ ]]; then
    echo "$1" | sed "s#=\(.*\)#='\1'#"
  elif [[ "$1" =~ ^-+[a-zA-Z0-9_\-]+$ ]]; then
    echo "$1"
  else
    echo "'$1'"
  fi
}
# ViashRemoveFlags: Remove leading flag
# $1     : string with a possible leading flag
# return : string without possible leading flag
# examples:
#   ViashRemoveFlags --foo=bar  # returns bar
function ViashRemoveFlags {
  echo "$1" | sed 's/^--*[a-zA-Z0-9_\-]*=//'
}
# ViashSourceDir: return the path of a bash file, following symlinks
# usage   : ViashSourceDir ${BASH_SOURCE[0]}
# $1      : Should always be set to ${BASH_SOURCE[0]}
# returns : The absolute path of the bash file
function ViashSourceDir {
  SOURCE="$1"
  while [ -h "$SOURCE" ]; do
    DIR="$( cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd )"
    SOURCE="$(readlink "$SOURCE")"
    [[ $SOURCE != /* ]] && SOURCE="$DIR/$SOURCE"
  done
  cd -P "$( dirname "$SOURCE" )" >/dev/null 2>&1 && pwd
}
# ViashFindTargetDir: return the path of the '.build.yaml' file, following symlinks
# usage   : ViashFindTargetDir 'ScriptPath'
# $1      : The location from where to start the upward search
# returns : The absolute path of the '.build.yaml' file
function ViashFindTargetDir {
  SOURCE="$1"
  while [[ "$SOURCE" != "" && ! -e "$SOURCE/.build.yaml" ]]; do
    SOURCE=${SOURCE%/*}
  done
  echo $SOURCE
}
# see https://en.wikipedia.org/wiki/Syslog#Severity_level
VIASH_LOGCODE_EMERGENCY=0
VIASH_LOGCODE_ALERT=1
VIASH_LOGCODE_CRITICAL=2
VIASH_LOGCODE_ERROR=3
VIASH_LOGCODE_WARNING=4
VIASH_LOGCODE_NOTICE=5
VIASH_LOGCODE_INFO=6
VIASH_LOGCODE_DEBUG=7
VIASH_VERBOSITY=$VIASH_LOGCODE_NOTICE

# ViashLog: Log events depending on the verbosity level
# usage: ViashLog 1 alert Oh no something went wrong!
# $1: required verbosity level
# $2: display tag
# $3+: messages to display
# stdout: Your input, prepended by '[$2] '.
function ViashLog {
  local required_level="$1"
  local display_tag="$2"
  shift 2
  if [ $VIASH_VERBOSITY -ge $required_level ]; then
    >&2 echo "[$display_tag]" "$@"
  fi
}

# ViashEmergency: log events when the system is unstable
# usage: ViashEmergency Oh no something went wrong.
# stdout: Your input, prepended by '[emergency] '.
function ViashEmergency {
  ViashLog $VIASH_LOGCODE_EMERGENCY emergency "$@"
}

# ViashAlert: log events when actions must be taken immediately (e.g. corrupted system database)
# usage: ViashAlert Oh no something went wrong.
# stdout: Your input, prepended by '[alert] '.
function ViashAlert {
  ViashLog $VIASH_LOGCODE_ALERT alert "$@"
}

# ViashCritical: log events when a critical condition occurs
# usage: ViashCritical Oh no something went wrong.
# stdout: Your input, prepended by '[critical] '.
function ViashCritical {
  ViashLog $VIASH_LOGCODE_CRITICAL critical "$@"
}

# ViashError: log events when an error condition occurs
# usage: ViashError Oh no something went wrong.
# stdout: Your input, prepended by '[error] '.
function ViashError {
  ViashLog $VIASH_LOGCODE_ERROR error "$@"
}

# ViashWarning: log potentially abnormal events
# usage: ViashWarning Something may have gone wrong.
# stdout: Your input, prepended by '[warning] '.
function ViashWarning {
  ViashLog $VIASH_LOGCODE_WARNING warning "$@"
}

# ViashNotice: log significant but normal events
# usage: ViashNotice This just happened.
# stdout: Your input, prepended by '[notice] '.
function ViashNotice {
  ViashLog $VIASH_LOGCODE_NOTICE notice "$@"
}

# ViashInfo: log normal events
# usage: ViashInfo This just happened.
# stdout: Your input, prepended by '[info] '.
function ViashInfo {
  ViashLog $VIASH_LOGCODE_INFO info "$@"
}

# ViashDebug: log all events, for debugging purposes
# usage: ViashDebug This just happened.
# stdout: Your input, prepended by '[debug] '.
function ViashDebug {
  ViashLog $VIASH_LOGCODE_DEBUG debug "$@"
}

# find source folder of this component
VIASH_META_RESOURCES_DIR=`ViashSourceDir ${BASH_SOURCE[0]}`

# find the root of the built components & dependencies
VIASH_TARGET_DIR=`ViashFindTargetDir $VIASH_META_RESOURCES_DIR`

# define meta fields
VIASH_META_FUNCTIONALITY_NAME="jn_ap_op2"
VIASH_META_EXECUTABLE="$VIASH_META_RESOURCES_DIR/$VIASH_META_FUNCTIONALITY_NAME"
VIASH_META_CONFIG="$VIASH_META_RESOURCES_DIR/.config.vsh.yaml"
VIASH_META_TEMP_DIR="$VIASH_TEMP"


# ViashHelp: Display helpful explanation about this executable
function ViashHelp {
  echo "jn_ap_op2 main_build"
  echo ""
  echo "Arguments:"
  echo "    --de_train"
  echo "        type: file, file must exist"
  echo "        example: resources/neurips-2023-data/de_train.parquet"
  echo ""
  echo "    --de_train_h5ad"
  echo "        type: file, file must exist"
  echo "        example: resources/neurips-2023-data/de_train.h5ad"
  echo ""
  echo "    --id_map"
  echo "        type: file, required parameter, file must exist"
  echo "        example: resources/neurips-2023-data/id_map.csv"
  echo ""
  echo "    --output"
  echo "        type: file, required parameter, output, file must exist"
  echo "        example: resources/neurips-2023-data/prediction.parquet"
  echo ""
  echo "    --n_replica"
  echo "        type: integer"
  echo "        default: 10"
  echo ""
  echo "    --submission_names"
  echo "        type: string, multiple values allowed"
  echo "        default: dl40;dl200"
}

# initialise array
VIASH_POSITIONAL_ARGS=''
VIASH_MODE='run'

while [[ $# -gt 0 ]]; do
    case "$1" in
        -h|--help)
            ViashHelp
            exit
            ;;
        ---v|---verbose)
            let "VIASH_VERBOSITY=VIASH_VERBOSITY+1"
            shift 1
            ;;
        ---verbosity)
            VIASH_VERBOSITY="$2"
            shift 2
            ;;
        ---verbosity=*)
            VIASH_VERBOSITY="$(ViashRemoveFlags "$1")"
            shift 1
            ;;
        --version)
            echo "jn_ap_op2 main_build"
            exit
            ;;
        --de_train)
            [ -n "$VIASH_PAR_DE_TRAIN" ] && ViashError Bad arguments for option \'--de_train\': \'$VIASH_PAR_DE_TRAIN\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_DE_TRAIN="$2"
            [ $# -lt 2 ] && ViashError Not enough arguments passed to --de_train. Use "--help" to get more information on the parameters. && exit 1
            shift 2
            ;;
        --de_train=*)
            [ -n "$VIASH_PAR_DE_TRAIN" ] && ViashError Bad arguments for option \'--de_train=*\': \'$VIASH_PAR_DE_TRAIN\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_DE_TRAIN=$(ViashRemoveFlags "$1")
            shift 1
            ;;
        --de_train_h5ad)
            [ -n "$VIASH_PAR_DE_TRAIN_H5AD" ] && ViashError Bad arguments for option \'--de_train_h5ad\': \'$VIASH_PAR_DE_TRAIN_H5AD\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_DE_TRAIN_H5AD="$2"
            [ $# -lt 2 ] && ViashError Not enough arguments passed to --de_train_h5ad. Use "--help" to get more information on the parameters. && exit 1
            shift 2
            ;;
        --de_train_h5ad=*)
            [ -n "$VIASH_PAR_DE_TRAIN_H5AD" ] && ViashError Bad arguments for option \'--de_train_h5ad=*\': \'$VIASH_PAR_DE_TRAIN_H5AD\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_DE_TRAIN_H5AD=$(ViashRemoveFlags "$1")
            shift 1
            ;;
        --id_map)
            [ -n "$VIASH_PAR_ID_MAP" ] && ViashError Bad arguments for option \'--id_map\': \'$VIASH_PAR_ID_MAP\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_ID_MAP="$2"
            [ $# -lt 2 ] && ViashError Not enough arguments passed to --id_map. Use "--help" to get more information on the parameters. && exit 1
            shift 2
            ;;
        --id_map=*)
            [ -n "$VIASH_PAR_ID_MAP" ] && ViashError Bad arguments for option \'--id_map=*\': \'$VIASH_PAR_ID_MAP\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_ID_MAP=$(ViashRemoveFlags "$1")
            shift 1
            ;;
        --output)
            [ -n "$VIASH_PAR_OUTPUT" ] && ViashError Bad arguments for option \'--output\': \'$VIASH_PAR_OUTPUT\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_OUTPUT="$2"
            [ $# -lt 2 ] && ViashError Not enough arguments passed to --output. Use "--help" to get more information on the parameters. && exit 1
            shift 2
            ;;
        --output=*)
            [ -n "$VIASH_PAR_OUTPUT" ] && ViashError Bad arguments for option \'--output=*\': \'$VIASH_PAR_OUTPUT\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_OUTPUT=$(ViashRemoveFlags "$1")
            shift 1
            ;;
        --n_replica)
            [ -n "$VIASH_PAR_N_REPLICA" ] && ViashError Bad arguments for option \'--n_replica\': \'$VIASH_PAR_N_REPLICA\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_N_REPLICA="$2"
            [ $# -lt 2 ] && ViashError Not enough arguments passed to --n_replica. Use "--help" to get more information on the parameters. && exit 1
            shift 2
            ;;
        --n_replica=*)
            [ -n "$VIASH_PAR_N_REPLICA" ] && ViashError Bad arguments for option \'--n_replica=*\': \'$VIASH_PAR_N_REPLICA\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_PAR_N_REPLICA=$(ViashRemoveFlags "$1")
            shift 1
            ;;
        --submission_names)
            if [ -z "$VIASH_PAR_SUBMISSION_NAMES" ]; then
              VIASH_PAR_SUBMISSION_NAMES="$2"
            else
              VIASH_PAR_SUBMISSION_NAMES="$VIASH_PAR_SUBMISSION_NAMES;""$2"
            fi
            [ $# -lt 2 ] && ViashError Not enough arguments passed to --submission_names. Use "--help" to get more information on the parameters. && exit 1
            shift 2
            ;;
        --submission_names=*)
            if [ -z "$VIASH_PAR_SUBMISSION_NAMES" ]; then
              VIASH_PAR_SUBMISSION_NAMES=$(ViashRemoveFlags "$1")
            else
              VIASH_PAR_SUBMISSION_NAMES="$VIASH_PAR_SUBMISSION_NAMES;"$(ViashRemoveFlags "$1")
            fi
            shift 1
            ;;
        ---cpus)
            [ -n "$VIASH_META_CPUS" ] && ViashError Bad arguments for option \'---cpus\': \'$VIASH_META_CPUS\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_META_CPUS="$2"
            [ $# -lt 2 ] && ViashError Not enough arguments passed to ---cpus. Use "--help" to get more information on the parameters. && exit 1
            shift 2
            ;;
        ---cpus=*)
            [ -n "$VIASH_META_CPUS" ] && ViashError Bad arguments for option \'---cpus=*\': \'$VIASH_META_CPUS\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_META_CPUS=$(ViashRemoveFlags "$1")
            shift 1
            ;;
        ---memory)
            [ -n "$VIASH_META_MEMORY" ] && ViashError Bad arguments for option \'---memory\': \'$VIASH_META_MEMORY\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_META_MEMORY="$2"
            [ $# -lt 2 ] && ViashError Not enough arguments passed to ---memory. Use "--help" to get more information on the parameters. && exit 1
            shift 2
            ;;
        ---memory=*)
            [ -n "$VIASH_META_MEMORY" ] && ViashError Bad arguments for option \'---memory=*\': \'$VIASH_META_MEMORY\' \& \'$2\' - you should provide exactly one argument for this option. && exit 1
            VIASH_META_MEMORY=$(ViashRemoveFlags "$1")
            shift 1
            ;;
        *)  # positional arg or unknown option
            # since the positional args will be eval'd, can we always quote, instead of using ViashQuote
            VIASH_POSITIONAL_ARGS="$VIASH_POSITIONAL_ARGS '$1'"
            [[ $1 == -* ]] && ViashWarning $1 looks like a parameter but is not a defined parameter and will instead be treated as a positional argument. Use "--help" to get more information on the parameters.
            shift # past argument
            ;;
    esac
done

# parse positional parameters
eval set -- $VIASH_POSITIONAL_ARGS


# setting computational defaults

# helper function for parsing memory strings
function ViashMemoryAsBytes {
  local memory=`echo "$1" | tr '[:upper:]' '[:lower:]' | tr -d '[:space:]'`
  local memory_regex='^([0-9]+)([kmgtp]b?|b)$'
  if [[ $memory =~ $memory_regex ]]; then
    local number=${memory/[^0-9]*/}
    local symbol=${memory/*[0-9]/}
    
    case $symbol in
      b)      memory_b=$number ;;
      kb|k)   memory_b=$(( $number * 1024 )) ;;
      mb|m)   memory_b=$(( $number * 1024 * 1024 )) ;;
      gb|g)   memory_b=$(( $number * 1024 * 1024 * 1024 )) ;;
      tb|t)   memory_b=$(( $number * 1024 * 1024 * 1024 * 1024 )) ;;
      pb|p)   memory_b=$(( $number * 1024 * 1024 * 1024 * 1024 * 1024 )) ;;
    esac
    echo "$memory_b"
  fi
}
# compute memory in different units
if [ ! -z ${VIASH_META_MEMORY+x} ]; then
  VIASH_META_MEMORY_B=`ViashMemoryAsBytes $VIASH_META_MEMORY`
  # do not define other variables if memory_b is an empty string
  if [ ! -z "$VIASH_META_MEMORY_B" ]; then
    VIASH_META_MEMORY_KB=$(( ($VIASH_META_MEMORY_B+1023) / 1024 ))
    VIASH_META_MEMORY_MB=$(( ($VIASH_META_MEMORY_KB+1023) / 1024 ))
    VIASH_META_MEMORY_GB=$(( ($VIASH_META_MEMORY_MB+1023) / 1024 ))
    VIASH_META_MEMORY_TB=$(( ($VIASH_META_MEMORY_GB+1023) / 1024 ))
    VIASH_META_MEMORY_PB=$(( ($VIASH_META_MEMORY_TB+1023) / 1024 ))
  else
    # unset memory if string is empty
    unset $VIASH_META_MEMORY_B
  fi
fi
# unset nproc if string is empty
if [ -z "$VIASH_META_CPUS" ]; then
  unset $VIASH_META_CPUS
fi


# check whether required parameters exist
if [ -z ${VIASH_PAR_ID_MAP+x} ]; then
  ViashError '--id_map' is a required argument. Use "--help" to get more information on the parameters.
  exit 1
fi
if [ -z ${VIASH_PAR_OUTPUT+x} ]; then
  ViashError '--output' is a required argument. Use "--help" to get more information on the parameters.
  exit 1
fi
if [ -z ${VIASH_META_FUNCTIONALITY_NAME+x} ]; then
  ViashError 'functionality_name' is a required argument. Use "--help" to get more information on the parameters.
  exit 1
fi
if [ -z ${VIASH_META_RESOURCES_DIR+x} ]; then
  ViashError 'resources_dir' is a required argument. Use "--help" to get more information on the parameters.
  exit 1
fi
if [ -z ${VIASH_META_EXECUTABLE+x} ]; then
  ViashError 'executable' is a required argument. Use "--help" to get more information on the parameters.
  exit 1
fi
if [ -z ${VIASH_META_CONFIG+x} ]; then
  ViashError 'config' is a required argument. Use "--help" to get more information on the parameters.
  exit 1
fi
if [ -z ${VIASH_META_TEMP_DIR+x} ]; then
  ViashError 'temp_dir' is a required argument. Use "--help" to get more information on the parameters.
  exit 1
fi

# filling in defaults
if [ -z ${VIASH_PAR_N_REPLICA+x} ]; then
  VIASH_PAR_N_REPLICA="10"
fi
if [ -z ${VIASH_PAR_SUBMISSION_NAMES+x} ]; then
  VIASH_PAR_SUBMISSION_NAMES="dl40;dl200"
fi

# check whether required files exist
if [ ! -z "$VIASH_PAR_DE_TRAIN" ] && [ ! -e "$VIASH_PAR_DE_TRAIN" ]; then
  ViashError "Input file '$VIASH_PAR_DE_TRAIN' does not exist."
  exit 1
fi
if [ ! -z "$VIASH_PAR_DE_TRAIN_H5AD" ] && [ ! -e "$VIASH_PAR_DE_TRAIN_H5AD" ]; then
  ViashError "Input file '$VIASH_PAR_DE_TRAIN_H5AD' does not exist."
  exit 1
fi
if [ ! -z "$VIASH_PAR_ID_MAP" ] && [ ! -e "$VIASH_PAR_ID_MAP" ]; then
  ViashError "Input file '$VIASH_PAR_ID_MAP' does not exist."
  exit 1
fi

# check whether parameters values are of the right type
if [[ -n "$VIASH_PAR_N_REPLICA" ]]; then
  if ! [[ "$VIASH_PAR_N_REPLICA" =~ ^[-+]?[0-9]+$ ]]; then
    ViashError '--n_replica' has to be an integer. Use "--help" to get more information on the parameters.
    exit 1
  fi
fi
if [[ -n "$VIASH_META_CPUS" ]]; then
  if ! [[ "$VIASH_META_CPUS" =~ ^[-+]?[0-9]+$ ]]; then
    ViashError 'cpus' has to be an integer. Use "--help" to get more information on the parameters.
    exit 1
  fi
fi
if [[ -n "$VIASH_META_MEMORY_B" ]]; then
  if ! [[ "$VIASH_META_MEMORY_B" =~ ^[-+]?[0-9]+$ ]]; then
    ViashError 'memory_b' has to be a long. Use "--help" to get more information on the parameters.
    exit 1
  fi
fi
if [[ -n "$VIASH_META_MEMORY_KB" ]]; then
  if ! [[ "$VIASH_META_MEMORY_KB" =~ ^[-+]?[0-9]+$ ]]; then
    ViashError 'memory_kb' has to be a long. Use "--help" to get more information on the parameters.
    exit 1
  fi
fi
if [[ -n "$VIASH_META_MEMORY_MB" ]]; then
  if ! [[ "$VIASH_META_MEMORY_MB" =~ ^[-+]?[0-9]+$ ]]; then
    ViashError 'memory_mb' has to be a long. Use "--help" to get more information on the parameters.
    exit 1
  fi
fi
if [[ -n "$VIASH_META_MEMORY_GB" ]]; then
  if ! [[ "$VIASH_META_MEMORY_GB" =~ ^[-+]?[0-9]+$ ]]; then
    ViashError 'memory_gb' has to be a long. Use "--help" to get more information on the parameters.
    exit 1
  fi
fi
if [[ -n "$VIASH_META_MEMORY_TB" ]]; then
  if ! [[ "$VIASH_META_MEMORY_TB" =~ ^[-+]?[0-9]+$ ]]; then
    ViashError 'memory_tb' has to be a long. Use "--help" to get more information on the parameters.
    exit 1
  fi
fi
if [[ -n "$VIASH_META_MEMORY_PB" ]]; then
  if ! [[ "$VIASH_META_MEMORY_PB" =~ ^[-+]?[0-9]+$ ]]; then
    ViashError 'memory_pb' has to be a long. Use "--help" to get more information on the parameters.
    exit 1
  fi
fi

# create parent directories of output files, if so desired
if [ ! -z "$VIASH_PAR_OUTPUT" ] && [ ! -d "$(dirname "$VIASH_PAR_OUTPUT")" ]; then
  mkdir -p "$(dirname "$VIASH_PAR_OUTPUT")"
fi


# set dependency paths


ViashDebug "Running command: bash"
cat << VIASHEOF | bash
set -e
tempscript=\$(mktemp "$VIASH_META_TEMP_DIR/viash-run-jn_ap_op2-XXXXXX").py
function clean_up {
  rm "\$tempscript"
}
function interrupt {
  echo -e "\nCTRL-C Pressed..."
  exit 1
}
trap clean_up EXIT
trap interrupt INT SIGINT
cat > "\$tempscript" << 'VIASHMAIN'
# This script is based an IPython notebook:
# https://github.com/AntoinePassemiers/Open-Challenges-Single-Cell-Perturbations/blob/master/op2-de-dl.ipynb

import pandas as pd
import os
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # Make PyTorch deterministic on GPU
import json
import math
import random
import warnings
import collections
from typing import Dict, List, Tuple, Optional, Generator
import numpy as np
import pandas as pd
import tqdm
import torch
import category_encoders

# local import
def plant_seed(seed: int, USE_GPU:bool = True) -> None:
    """Set seed for reproducibility purposes.
    
    Applies to the \`random\`, \`numpy\` and \`torch\` packages.
    
    Args:
        seed: Seed state.
    """
    np.random.seed(seed)
    torch.manual_seed(seed)
    if USE_GPU:
        torch.cuda.manual_seed_all(seed)



class MultiOutputTargetEncoder:
    """Multi-output target encoder.
    
    Each input (categorical) feature will be encoded based on each (continuous) output variable.
    
    Attributes:
        encoders: List of encoders, of shape \`n_genes\`.
    """
    
    def __init__(self):
        self.encoders: List[category_encoders.leave_one_out.LeaveOneOutEncoder] = []
        
    @staticmethod
    def new_encoder() -> category_encoders.leave_one_out.LeaveOneOutEncoder:
        """Instantiates a new gene-specific target encoder.
        
        Returns:
            New instance of a target encoder.
        """
        return category_encoders.leave_one_out.LeaveOneOutEncoder(return_df=False)
    
    def fit(self, X: np.ndarray, y: np.ndarray) -> None:
        """Fit the encoders for each input feature and output variable.
        
        Args:
            X: Array of shape \`(n, n_features)\` containing categories as strings or integers.
                Typical, \`n_features\` is equal to 2 (cell type + compound).
            y: Array of shape \`(n, n_genes)\` containing the DE values for all the genes.
        """
        self.encoders = []
        for j in tqdm.tqdm(range(y.shape[1]), desc='fit LOO encoders'):
            self.encoders.append(MultiOutputTargetEncoder.new_encoder())
            self.encoders[-1].fit(X, y[:, j])
    
    def transform(self, X: np.ndarray) -> np.ndarray:
        """Encodes the categories. Assumes the encoders have already been fitted.
        
        Args:
            X: Array of shape \`(n, n_features)\` containing categories as strings or integers.
        
        Returns:
            Array of shape \`(n, n_genes, n_features)\` containing the encoding of each input
                feature with respect to each output variable.
        """
        Z = []
        for encoder in tqdm.tqdm(self.encoders, desc='transform LOO encoders'):
            y_hat = encoder.transform(X)
            Z.append(y_hat)
        Z = np.asarray(Z)
        return np.transpose(Z, (1, 0, 2))

class NN(torch.nn.Module):
    """Deep learning architecture composed of 2 modules: a sample-centric MLP
    and a gene-centric MLP.
    
    Attributes:
        n_genes: Total number of genes
        n_input_channels: Number of input channels. When using target encoding for both
            cell types and compounds, this results in one channel for the cell type and
            one for the compound.
        n_output_channels: Number of channels outputed by the sample-centric MLP.
        mlp1: Sample-centric MLP.
        mlp2: Gene-centric MLP.
        net1: Sparse MLP defined by the gene-pathway network.
        net2: Sparse MLP defined by the co-accessibility network.
        net3: Sparse MLP defined by the gene regulatory network.
    """
    
    def __init__(self, n_genes: int, n_input_channels: int):
        torch.nn.Module.__init__(self)
        
        # Total number of genes
        self.n_genes: int = n_genes
            
        # Number of input channels = 2 (cell type + compound)
        self.n_input_channels: int = n_input_channels
            
        # Number of channels outputed by the first MLP = 2 (an arbitrary number)
        self.n_output_channels: int = 2
            
        # No bias term is used in the full-connected layers, to encourage the model
        # to learn an output distribution for which the modal value is 0 (for most genes).
        bias = False
        
        # First MLP module to treat each row of the original data matrix as individual observation.
        # In other words,the MLP processes each (cell_type, compound) combination separately.
        # Shape: (batch_size, n_input_channels*n_genes) -> (batch_size, n_output_channels*n_genes)
        self.mlp1 = torch.nn.Sequential(

            torch.nn.Linear(self.n_genes * self.n_input_channels, 16, bias=bias),
            torch.nn.PReLU(num_parameters=16),
            
            torch.nn.Linear(16, 128, bias=bias),
            torch.nn.PReLU(num_parameters=128),
            
            torch.nn.Linear(128, 128, bias=bias),
            torch.nn.PReLU(num_parameters=128),
            
            torch.nn.Linear(128, 64, bias=bias),
            torch.nn.PReLU(num_parameters=64),
            
            torch.nn.Linear(64, 32, bias=bias),
            torch.nn.PReLU(num_parameters=32),

            torch.nn.Linear(32, 16, bias=bias),
            torch.nn.PReLU(num_parameters=16),
            
            torch.nn.Linear(16, self.n_genes * self.n_output_channels, bias=bias)
        )

        # Second MLP module treats each sample and gene as individual observation.
        # In other words,the MLP processes each (cell_type, compound, gene_name) combination separately.
        # Shape: (batch_size, n_channels) -> (batch_size, 1)
        h = 12
        self.mlp2 = torch.nn.Sequential(

            torch.nn.Linear(self.n_input_channels + self.n_output_channels, h, bias=bias),
            torch.nn.PReLU(num_parameters=h),
            
            torch.nn.Linear(h, h, bias=bias),
            torch.nn.PReLU(num_parameters=h),
            
            torch.nn.Linear(h, h, bias=bias),
            torch.nn.PReLU(num_parameters=h),
            
            torch.nn.Linear(h, h, bias=bias),
            torch.nn.PReLU(num_parameters=h),
            
            torch.nn.Linear(h, 1, bias=bias)
        )
        
        self.net1 = None
        self.net2 = None
        self.net3 = None
        
        # Xavier initialization
        def init_weights(m):
            if isinstance(m, torch.nn.Linear):
                torch.nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    m.bias.data.fill_(0.001)
        self.mlp1.apply(init_weights)
        self.mlp2.apply(init_weights)
        
    def forward(self, X: torch.Tensor) -> torch.Tensor:
        """Predict DE values from the categorical target encoding of DE values.
        
        Args:
            X: Categorical target encoding of cell types and compounds based on DE values.
                \`X\` is a tensor of shape \`(batch_size, n_genes, n_input_channels)\`,
                where \`n_input_channels\` is the number of target-encoded features.
                In the present case, we consider only the cell type and the compound.
        
        Returns:
            Estimated DE values.
        """
        
        # Reshape from (batch_size, n_genes, n_input_channels) to 
        # (batch_size, n_genes*n_input_channels) and process with sample-centric MLP
        Y = self.mlp1(X.reshape(len(X), -1))
        
        # Reshape from (batch_size, n_genes*n_output_channels) to
        # (batch_size*n_genes, n_output_channels)
        Y = Y.reshape(-1, self.n_output_channels)
        
        # Concatenate input and output channels into (batch_size, n_genes*n_channels)
        # and process with gene-centric MLP
        Y = torch.cat((X.reshape(-1, self.n_input_channels), Y), dim=1)
        Y = self.mlp2(Y)
        
        # Output is of shape (batch_size, n_genes)
        Y = Y.reshape(len(X), -1)

        return Y

def background_noise(
    *size: int,
    cutoff: float = 0.001,
    device: str = 'gpu',
    generator: torch.Generator = None) -> torch.Tensor:
    """Generates random DE values under the null hypothesis.

    In the absence of any biological signal, p-values can be expected to be 
    uniformly distributed. Also, positive and negative DE values are equally likely.

    Args:
        size: shape of the output tensor.
        cutoff: Significance threshold used to make sure we don't introduce huge outliers in the data.
            This cutoff does not have a real statistical meaning, and is only meant for numerical stability.
            P-values will be randomly and uniformly sampled from the \`\`[cutoff, 1]\`\` interval.
        device: Device where to do the computations (cpu or gpu).
        generator: RNG used for sampling.

    Returns:
        Random DE values, stored in a tensor of the desired shape.
    """
    sign = 2 * torch.randint(0, 2, size, device=device) - 1

    return sign * torch.log10(cutoff +  torch.rand(*size, generator=generator, device=device) * (1. - cutoff))


def train(
        X: torch.Tensor,
        Y: torch.Tensor,
        idx_train: np.ndarray,
        seed: int,
        n_iter: int = 40,  # 200
        USE_GPU: bool = True,
        **kwargs) -> NN:
    """Trains a neural network and returns it.
    
    Args:
        X: Input features. A tensor of shape \`(n, n_genes, n_input_channels)\`, where \`n\`
            is the total number of rows in the original data matrix.
        Y: Output variables. A tensor of shape \`(n, n_genes)\`.
        idx_train: Indices of the training data.
        seed: Seed for reproducibility purposes.
        n_iter: Number of epochs.
        kwargs: Optional arguments to pass to the constructor of the model.
    
    Returns:
        Trained model.
    """
    
    idx_train = np.copy(idx_train)
    
    # Initialize RNG
    rng = np.random.default_rng(seed=seed)
    
    plant_seed(seed)
    
    # Initialize NN
    n_input_channels = X.size()[2]
    model = NN(X.shape[1], n_input_channels, **kwargs)
    if USE_GPU:
        model.cuda()
        device='cuda'
    else:
        device=None
    generator = torch.Generator(device=device).manual_seed(seed)
    # Initialize optimizer and scheduler
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, eps=1e-7)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='min', factor=0.9, patience=5, verbose=False, threshold=0.0001,
            threshold_mode='rel', cooldown=2, min_lr=1e-5, eps=1e-08)
    
    # Place data on GPU
    if USE_GPU:
        X = X.cuda()
        Y = Y.cuda()
    
    pbar = tqdm.tqdm(range(n_iter))
    for epoch in pbar:
        total_loss, baseline_total_loss = 0, 0
        rng.shuffle(idx_train)
        for it_idx in np.array_split(idx_train, 200):  # 120
            
            # Reset gradients
            optimizer.zero_grad()
            
            # Create batch
            Y_target = Y[it_idx, :]
            if USE_GPU:
                Y_target = Y_target.cuda()
            
            # Sample from the null distribution and add background noise to the targets
            Y_target = Y_target + 0.5 * background_noise(*Y_target.size(), device=X.device, generator=generator)
            
            # Forward pass
            x = X[it_idx]
            if USE_GPU:
                x = x.cuda()
            Y_pred = model.forward(x)
            
            # Compute loss (mean absolute error) in a differentiable fashion
            loss = torch.mean(torch.abs(Y_target - Y_pred))
            
            # Backward pass
            loss.backward()
            
            # Update NN parameters
            optimizer.step()
            
            # Update training MRRMSE, and also update MRRMSE for the baseline (zero) predictor
            # for comparison purposes
            mrrmse = torch.sum(torch.sqrt(torch.mean(torch.square(Y_target - Y_pred), dim=1)))
            baseline_mrrmse = torch.sum(torch.sqrt(torch.mean(torch.square(Y_target), dim=1)))
            total_loss += mrrmse.item()
            baseline_total_loss += baseline_mrrmse.item()
            
        # Compute relative error. Relative error is < 1 when the model performs better than
        # the baseline on the training data.
        rel_error = total_loss / baseline_total_loss
        
        # Update learning rate
        scheduler.step(rel_error)
        
        # Show relative error
        pbar.set_description(f'{rel_error:.3f}')
    return model

## VIASH START
# The following code has been auto-generated by Viash.
par = {
  'de_train': $( if [ ! -z ${VIASH_PAR_DE_TRAIN+x} ]; then echo "r'${VIASH_PAR_DE_TRAIN//\'/\'\"\'\"r\'}'"; else echo None; fi ),
  'de_train_h5ad': $( if [ ! -z ${VIASH_PAR_DE_TRAIN_H5AD+x} ]; then echo "r'${VIASH_PAR_DE_TRAIN_H5AD//\'/\'\"\'\"r\'}'"; else echo None; fi ),
  'id_map': $( if [ ! -z ${VIASH_PAR_ID_MAP+x} ]; then echo "r'${VIASH_PAR_ID_MAP//\'/\'\"\'\"r\'}'"; else echo None; fi ),
  'output': $( if [ ! -z ${VIASH_PAR_OUTPUT+x} ]; then echo "r'${VIASH_PAR_OUTPUT//\'/\'\"\'\"r\'}'"; else echo None; fi ),
  'n_replica': $( if [ ! -z ${VIASH_PAR_N_REPLICA+x} ]; then echo "int(r'${VIASH_PAR_N_REPLICA//\'/\'\"\'\"r\'}')"; else echo None; fi ),
  'submission_names': $( if [ ! -z ${VIASH_PAR_SUBMISSION_NAMES+x} ]; then echo "r'${VIASH_PAR_SUBMISSION_NAMES//\'/\'\"\'\"r\'}'.split(';')"; else echo None; fi )
}
meta = {
  'functionality_name': $( if [ ! -z ${VIASH_META_FUNCTIONALITY_NAME+x} ]; then echo "r'${VIASH_META_FUNCTIONALITY_NAME//\'/\'\"\'\"r\'}'"; else echo None; fi ),
  'resources_dir': $( if [ ! -z ${VIASH_META_RESOURCES_DIR+x} ]; then echo "r'${VIASH_META_RESOURCES_DIR//\'/\'\"\'\"r\'}'"; else echo None; fi ),
  'executable': $( if [ ! -z ${VIASH_META_EXECUTABLE+x} ]; then echo "r'${VIASH_META_EXECUTABLE//\'/\'\"\'\"r\'}'"; else echo None; fi ),
  'config': $( if [ ! -z ${VIASH_META_CONFIG+x} ]; then echo "r'${VIASH_META_CONFIG//\'/\'\"\'\"r\'}'"; else echo None; fi ),
  'temp_dir': $( if [ ! -z ${VIASH_META_TEMP_DIR+x} ]; then echo "r'${VIASH_META_TEMP_DIR//\'/\'\"\'\"r\'}'"; else echo None; fi ),
  'cpus': $( if [ ! -z ${VIASH_META_CPUS+x} ]; then echo "int(r'${VIASH_META_CPUS//\'/\'\"\'\"r\'}')"; else echo None; fi ),
  'memory_b': $( if [ ! -z ${VIASH_META_MEMORY_B+x} ]; then echo "int(r'${VIASH_META_MEMORY_B//\'/\'\"\'\"r\'}')"; else echo None; fi ),
  'memory_kb': $( if [ ! -z ${VIASH_META_MEMORY_KB+x} ]; then echo "int(r'${VIASH_META_MEMORY_KB//\'/\'\"\'\"r\'}')"; else echo None; fi ),
  'memory_mb': $( if [ ! -z ${VIASH_META_MEMORY_MB+x} ]; then echo "int(r'${VIASH_META_MEMORY_MB//\'/\'\"\'\"r\'}')"; else echo None; fi ),
  'memory_gb': $( if [ ! -z ${VIASH_META_MEMORY_GB+x} ]; then echo "int(r'${VIASH_META_MEMORY_GB//\'/\'\"\'\"r\'}')"; else echo None; fi ),
  'memory_tb': $( if [ ! -z ${VIASH_META_MEMORY_TB+x} ]; then echo "int(r'${VIASH_META_MEMORY_TB//\'/\'\"\'\"r\'}')"; else echo None; fi ),
  'memory_pb': $( if [ ! -z ${VIASH_META_MEMORY_PB+x} ]; then echo "int(r'${VIASH_META_MEMORY_PB//\'/\'\"\'\"r\'}')"; else echo None; fi )
}
dep = {
  
}

## VIASH END
print('Reading input files', flush=True)
de_train = pd.read_parquet(par["de_train"])
id_map = pd.read_csv(par["id_map"])

gene_names = [col for col in de_train.columns if col not in {"cell_type", "sm_name", "sm_lincs_id", "SMILES", "split", "control", "index"}]

print('Preprocess data', flush=True)
SEED = 0xCAFE
USE_GPU = True
if USE_GPU and torch.cuda.is_available():
    print('using device: cuda')
else:
    print('using device: cpu')
    USE_GPU = False
    
# Make Python deterministic?
os.environ['PYTHONHASHSEED'] = str(int(SEED))

# Make PyTorch deterministic
torch.use_deterministic_algorithms(True)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
torch.backends.cudnn.enabled = False
torch.set_num_threads(1)
plant_seed(SEED, USE_GPU)

print('Data location', flush=True)
# Data location
cell_types = de_train['cell_type']
sm_names = de_train['sm_name']

data = de_train.drop(columns=["cell_type", "sm_name", "sm_lincs_id", "SMILES", "split", "control"]).to_numpy(dtype=float)

print('Train model', flush=True)
# ... train model ...
encoder = MultiOutputTargetEncoder()

encoder.fit(np.asarray([cell_types, sm_names]).T, data)

X = torch.FloatTensor(encoder.transform(np.asarray([cell_types, sm_names]).T))
X_submit = torch.FloatTensor(encoder.transform(np.asarray([id_map.cell_type, id_map.sm_name]).T))

if USE_GPU:
    X = X.cuda()

print('Generate predictions', flush=True)
# ... generate predictions ...

Y_submit_ensemble = []
for SUBMISSION_NAME in par["submission_names"]:
  #train the models and store them
  models = []
  for i in range(par["n_replica"] ):
      seed = i
      if SUBMISSION_NAME == 'dl40':
          model = train(X, torch.FloatTensor(data), np.arange(len(X)), seed, n_iter=40, USE_GPU=USE_GPU)
      elif SUBMISSION_NAME == 'dl200':
          model = train(X, torch.FloatTensor(data), np.arange(len(X)), seed, n_iter=200, USE_GPU=USE_GPU)
      else:
          model = train(X, torch.FloatTensor(data), np.arange(len(X)), seed, n_iter=40, USE_GPU=USE_GPU)
      model.eval()
      models.append(model)
      torch.cuda.empty_cache()
  # predict 
  Y_submit =  []
  for i, x in tqdm.tqdm(enumerate(X_submit), desc='Submission'):
    # Predict on test sample using a simple ensembling strategy:
    # take the median of the predictions across the different models
    y_hat = []
    for model in models:
        model = model.cpu()
        y_hat.append(np.squeeze(model.forward(x.unsqueeze(0)).cpu().data.numpy()))
    y_hat = np.median(y_hat, axis=0)

    values = [f'{x:.5f}' for x in y_hat]
    Y_submit.append(values)
    
  Y_submit_ensemble.append(np.asarray(Y_submit).astype(np.float32))
    
Y_submit_final = np.mean(Y_submit_ensemble, axis=0)

print('Write output to file', flush=True)
output = pd.DataFrame(
  Y_submit_final,
  index=id_map["id"],
  columns=gene_names
).reset_index()
output.to_parquet(par["output"])
VIASHMAIN
python -B "\$tempscript" &
wait "\$!"

VIASHEOF


# check whether required files exist
if [ ! -z "$VIASH_PAR_OUTPUT" ] && [ ! -e "$VIASH_PAR_OUTPUT" ]; then
  ViashError "Output file '$VIASH_PAR_OUTPUT' does not exist."
  exit 1
fi


exit 0
